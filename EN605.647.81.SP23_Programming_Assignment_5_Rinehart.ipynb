{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    #initialize perceptron class\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.delta_weights = np.zeros_like(weights)\n",
    "        self.bias = bias\n",
    "        self.delta_bias = 0\n",
    "        self.activity = 0\n",
    "        self.activation = 0\n",
    "        self.delta = 0\n",
    "    \n",
    "    #Calculate the activity value\n",
    "    def calc_activity(self, inputs):\n",
    "        self.activity = np.dot(inputs, self.weights) + self.bias\n",
    "        #print(\"activity: \", self.activity)\n",
    "    \n",
    "    #Calculate the activation function given the activity value using sigmoid function\n",
    "    def calc_activation(self, activity):\n",
    "        self.activation = 1/(1+np.exp(-1*self.activity))\n",
    "        #print(\"activation: \", self.activation)\n",
    "    \n",
    "    #Find the change needed in weights and bias\n",
    "    def set_delta_weights(self, inputs, eta, target):\n",
    "        self.delta = self.activation*(1-self.activation)*(target - self.activation)\n",
    "        for i in range(len(inputs)):\n",
    "            self.delta_weights[i] = inputs[i] * self.delta * eta\n",
    "        self.delta_bias =  self.delta * eta\n",
    "        #print(\"Bias: \", self.bias, \" Delta: \", self.delta, \" Eta: \", eta, \" Delta Bias: \", self.delta_bias)\n",
    "    \n",
    "    #update weights and bias\n",
    "    def update_weights(self):\n",
    "        #print(\"Weights: \", self.weights)\n",
    "        #print(self.delta_weights)\n",
    "        #print(\"Bias: \", self.bias)\n",
    "        #print(self.delta_bias)\n",
    "        self.weights += self.delta_weights\n",
    "        self.bias += self.delta_bias\n",
    "        #print(\"Updated bias: \", self.bias)\n",
    "    \n",
    "    #Call necessary functions to update perceptron using perceptron delta function process\n",
    "    def perceptron_delta(self, target, inputs):\n",
    "        self.target = target\n",
    "        self.calc_activity(inputs)\n",
    "        self.calc_activation(self.activity)\n",
    "        self.set_delta_weights(inputs, eta, target)\n",
    "        self.update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial parameters\n",
    "input_vector=[0.8,0.9]\n",
    "weight_vector = [0.24, 0.88]\n",
    "bias = 0\n",
    "eta = 5\n",
    "target = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Activation value:  0.7279\n",
      "Iteration 2 Activation value:  0.821\n",
      "Iteration 3 Activation value:  0.8526\n",
      "Iteration 4 Activation value:  0.8705\n",
      "Iteration 5 Activation value:  0.8824\n",
      "Iteration 6 Activation value:  0.891\n",
      "Iteration 7 Activation value:  0.8976\n",
      "Iteration 8 Activation value:  0.9029\n",
      "Iteration 9 Activation value:  0.9073\n",
      "Iteration 10 Activation value:  0.9109\n",
      "Iteration 11 Activation value:  0.914\n",
      "Iteration 12 Activation value:  0.9167\n",
      "Iteration 13 Activation value:  0.919\n",
      "Iteration 14 Activation value:  0.9211\n",
      "Iteration 15 Activation value:  0.923\n",
      "Iteration 16 Activation value:  0.9246\n",
      "Iteration 17 Activation value:  0.9261\n",
      "Iteration 18 Activation value:  0.9275\n",
      "Iteration 19 Activation value:  0.9287\n",
      "Iteration 20 Activation value:  0.9298\n",
      "Iteration 21 Activation value:  0.9309\n",
      "Iteration 22 Activation value:  0.9319\n",
      "Iteration 23 Activation value:  0.9327\n",
      "Iteration 24 Activation value:  0.9336\n",
      "Iteration 25 Activation value:  0.9343\n",
      "Iteration 26 Activation value:  0.9351\n",
      "Iteration 27 Activation value:  0.9357\n",
      "Iteration 28 Activation value:  0.9364\n",
      "Iteration 29 Activation value:  0.937\n",
      "Iteration 30 Activation value:  0.9375\n",
      "Iteration 31 Activation value:  0.938\n",
      "Iteration 32 Activation value:  0.9385\n",
      "Iteration 33 Activation value:  0.939\n",
      "Iteration 34 Activation value:  0.9394\n",
      "Iteration 35 Activation value:  0.9398\n",
      "Iteration 36 Activation value:  0.9402\n",
      "Iteration 37 Activation value:  0.9406\n",
      "Iteration 38 Activation value:  0.941\n",
      "Iteration 39 Activation value:  0.9413\n",
      "Iteration 40 Activation value:  0.9416\n",
      "Iteration 41 Activation value:  0.942\n",
      "Iteration 42 Activation value:  0.9422\n",
      "Iteration 43 Activation value:  0.9425\n",
      "Iteration 44 Activation value:  0.9428\n",
      "Iteration 45 Activation value:  0.9431\n",
      "Iteration 46 Activation value:  0.9433\n",
      "Iteration 47 Activation value:  0.9435\n",
      "Iteration 48 Activation value:  0.9438\n",
      "Iteration 49 Activation value:  0.944\n",
      "Iteration 50 Activation value:  0.9442\n",
      "Iteration 51 Activation value:  0.9444\n",
      "Iteration 52 Activation value:  0.9446\n",
      "Iteration 53 Activation value:  0.9447\n",
      "Iteration 54 Activation value:  0.9449\n",
      "Iteration 55 Activation value:  0.9451\n",
      "Iteration 56 Activation value:  0.9453\n",
      "Iteration 57 Activation value:  0.9454\n",
      "Iteration 58 Activation value:  0.9456\n",
      "Iteration 59 Activation value:  0.9457\n",
      "Iteration 60 Activation value:  0.9458\n",
      "Iteration 61 Activation value:  0.946\n",
      "Iteration 62 Activation value:  0.9461\n",
      "Iteration 63 Activation value:  0.9462\n",
      "Iteration 64 Activation value:  0.9463\n",
      "Iteration 65 Activation value:  0.9465\n",
      "Iteration 66 Activation value:  0.9466\n",
      "Iteration 67 Activation value:  0.9467\n",
      "Iteration 68 Activation value:  0.9468\n",
      "Iteration 69 Activation value:  0.9469\n",
      "Iteration 70 Activation value:  0.947\n",
      "Iteration 71 Activation value:  0.9471\n",
      "Iteration 72 Activation value:  0.9472\n",
      "Iteration 73 Activation value:  0.9472\n",
      "Iteration 74 Activation value:  0.9473\n",
      "Iteration 75 Activation value:  0.9474\n"
     ]
    }
   ],
   "source": [
    "#Create temporar\n",
    "Percep = Perceptron(weight_vector, bias)\n",
    "for i in range(0,75):\n",
    "    Percep.perceptron_delta(target, input_vector)\n",
    "    print(\"Iteration\", i+1 , \"Activation value: \", round(Percep.activation,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
